# ü§ñ Ferdynand

### Opis Projektu
Aplikacja sterujƒÖca robotem `Ferdynand`, opracowana we Flutterze, pozwala na bezdotykowe sterowanie ruchem robota. Aplikacja korzysta z rozpoznawania mowy i sensora zbli≈ºeniowego, aby zarzƒÖdzaƒá trybem ruchu robota w czasie rzeczywistym. W zale≈ºno≈õci od komend g≈Çosowych lub zbli≈ºenia siƒô do przeszkody, robot zmienia kierunek.

### Funkcjonalno≈õƒá
- **Rozpoznawanie Mowy**: `Ferdynand` rozpoznaje komendy g≈Çosowe takie jak "do przodu", "do ty≈Çu", "w lewo", "w prawo" i dostosowuje kierunek ruchu robota.
- **Wykrywanie Przeszk√≥d**: Sensor zbli≈ºeniowy wykrywa przeszkody na drodze robota. 
- **Wizualizacja Ruchu**: Ka≈ºdy tryb ruchu robota jest reprezentowany przez sekwencjƒô kwadrat√≥w, kt√≥ra odbierana jest przez fotodiody.
- **Bezdotykowa Obs≈Çuga**: Po uruchomieniu aplikacja nie wymaga dodatkowej interakcji ‚Äì ciƒÖgle nas≈Çuchuje komend g≈Çosowych i danych z sensora.

### Jak to Dzia≈Ça?
1. **Uruchomienie Aplikacji**  
   Po uruchomieniu aplikacji na urzƒÖdzeniu, nastƒôpuje automatyczne przyznanie wymaganych uprawnie≈Ñ do mikrofonu i robot zaczyna ruch "do przodu". Aplikacja nas≈Çuchuje komend g≈Çosowych i monitoruje otoczenie robota.

2. **Reakcja na Przeszkody**  
   Gdy sensor wykryje przeszkodƒô, robot automatycznie przechodzi w tryb "do ty≈Çu" na 3 sekundy, po czym wraca do trybu "do przodu", kontynuujƒÖc ruch. Pozwala to na unikanie przeszk√≥d bez potrzeby interwencji u≈ºytkownika.

3. **Komendy G≈Çosowe**  
   Aplikacja rozpoznaje komendy takie jak "do przodu", "do ty≈Çu", "w lewo" i "w prawo". Na ich podstawie aktualizowany jest kierunek ruchu robota. Po podaniu komendy aplikacja automatycznie prze≈ÇƒÖcza siƒô na nas≈Çuch kolejnych instrukcji, umo≈ºliwiajƒÖc p≈Çynne sterowanie bez dotykania ekranu.

### Wizualizacja i Wzorce Ruchu
- **Do Przodu**:
- 
  <br> <img src="https://github.com/user-attachments/assets/09f0421f-5194-432a-9e65-37628017c916" width="400"/>
- **Do Ty≈Çu**: 

  <br> <img src="https://github.com/user-attachments/assets/5932b3b6-2a50-47c0-8b1d-68d2e6d543d0" width="400"/>
- **W Lewo**: 

  <br> <img src="https://github.com/user-attachments/assets/bdf32996-5269-4022-b7b0-308f39893857" width="400"/>
- **W Prawo**:

  <br> <img src="https://github.com/user-attachments/assets/a74e4888-6d61-49ce-9e06-8ba1dd91738e" width="400"/>

### Technologie i Biblioteki
- **Flutter**: G≈Ç√≥wna technologia u≈ºyta do budowy aplikacji.
- **Permission Handler**: ZarzƒÖdzanie uprawnieniami dostƒôpu do mikrofonu, co jest niezbƒôdne dla rozpoznawania mowy.
- **Proximity Sensor**: Wykrywanie przeszk√≥d na drodze robota.
- **Speech-to-Text**: T≈Çumaczenie komend g≈Çosowych na tekst, kt√≥ry steruje ruchami robota.

### Struktura Projektu
Kod podzielony jest na modu≈Çy dla ≈Çatwiejszej dostƒôpno≈õci:
1. **Widget HomePage**: G≈Ç√≥wna strona aplikacji, wy≈õwietlajƒÖca status robota oraz bie≈ºƒÖcy tryb ruchu.
2. **Klasa Pattern**: Logika obs≈ÇugujƒÖca wzorce ruchu robota, w zale≈ºno≈õci od komend g≈Çosowych i danych z sensora.
3. **Klasa VoiceControl**: Modu≈Ç zarzƒÖdzajƒÖcy rozpoznawaniem mowy.
4. **Klasa Sensor**: Modu≈Ç do obs≈Çugi sensora zbli≈ºeniowego.

### Rozw√≥j
W przysz≈Ço≈õci projekt mo≈ºna rozszerzyƒá o:
- **Dodatkowe Komendy G≈Çosowe**: Rozpoznawanie bardziej z≈Ço≈ºonych instrukcji, takich jak "obr√≥t" czy "stop".
- **Zaawansowane Omijanie Przeszk√≥d**: Wprowadzenie algorytmu, kt√≥ry pozwala na bardziej zaawansowane omijanie przeszk√≥d.
- **Reakcje robota**: Wykorzystanie biblioteki Text-to-Speech, w celu reakcji np. po natrafieniu na przeszkodƒô.
